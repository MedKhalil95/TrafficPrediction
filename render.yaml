services:
  - type: web
    name: traffic-prediction
    env: python
    plan: free
    branch: main
    # Build: upgrade pip tools, try to install CPU PyTorch wheels first (recommended on Render),
    # then install the rest of requirements.
    buildCommand: |
      echo "== Python: $(python --version || echo 'not available')"
      pip install --upgrade pip setuptools wheel
      # Try to install CPU-only PyTorch (fastest and avoids CUDA). If that fails, fall back to normal pip install.
      pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision || pip install torch torchvision
      pip install -r requirements.txt
    # Start: point Gunicorn at the WSGI app exported by run.py (run.py contains `app = create_app()`).
    # Bind to Render's $PORT so Render can detect the service health, and use the provided $WEB_CONCURRENCY.
    startCommand: gunicorn run:app --bind 0.0.0.0:$PORT --workers $WEB_CONCURRENCY
    autoDeploy: true
    # A simple HTTP health check path
    healthCheckPath: /
    envVars:
      - key: PYTHONUNBUFFERED
        value: "true"
      # Increase Gunicorn timeout for slow cold starts (optional)
      - key: GUNICORN_CMD_ARGS
        value: "--timeout 120"